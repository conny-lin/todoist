{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual inputs\n",
    "testing_status = True\n",
    "# set start and end date\n",
    "startdate_string = '2022-08-22'\n",
    "entryduration = 7*4\n",
    "# create new or not\n",
    "update_Todoist = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from todoist_api_python.api import TodoistAPI\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'todoist-python - Routine-test.csv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# api token file name\n",
    "if testing_status:\n",
    "    todoist_token_fname = 'todoist_api_token_test.txt'\n",
    "    fname_inputcsv = 'todoist-python - Routine-test.csv'\n",
    "    fpath_inputcsv = os.path.join(os.getcwd(), fname_inputcsv)\n",
    "else:\n",
    "    todoist_token_fname = 'todoist_api_token.txt'\n",
    "    fname_inputcsv = 'todoist-python - Routines.csv'\n",
    "    fpath_inputcsv = os.path.join(os.getcwd(), fname_inputcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat label dictionary\n",
    "def get_label_dict(todoist_api):\n",
    "    api = TodoistAPI(todoist_api)\n",
    "    try:\n",
    "        labels = api.get_labels()\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "    # label into dictionary\n",
    "    label_dict = {}\n",
    "    for i in range(len(labels)):\n",
    "        label_dict[labels[i].name] = labels[i].id\n",
    "    return label_dict\n",
    "\n",
    "\n",
    "\n",
    "# creat project id dictionary\n",
    "def get_project_dict(todoist_api):\n",
    "    api = TodoistAPI(todoist_api)\n",
    "    try:\n",
    "        a = api.get_projects()\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "    # label into dictionary\n",
    "    d = {}\n",
    "    for i in range(len(a)):\n",
    "        d[a[i].name] = a[i].id\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "# creat section id dictionary from a project\n",
    "def get_section_dict_pjc(todoist_api, project_id):\n",
    "    api = TodoistAPI(todoist_api)\n",
    "    try:\n",
    "        a = api.get_sections(project_id=project_id)\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "    # put into dictionary\n",
    "    d = {}\n",
    "    for i in range(len(a)):\n",
    "        d[a[i].name] = a[i].id\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "# creat section id dictionaries\n",
    "def get_section_dict(todoist_api):\n",
    "    api = TodoistAPI(todoist_api)\n",
    "    try:\n",
    "        todoistpull = api.get_sections()\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "\n",
    "    # put in dictionaries\n",
    "    section_proj_dict = {}\n",
    "    section_name_dict = {}\n",
    "\n",
    "    for i in range(len(todoistpull)):\n",
    "        section_proj_dict[todoistpull[i].id] = todoistpull[i].project_id\n",
    "        section_name_dict[todoistpull[i].name] = todoistpull[i].id\n",
    "    return section_proj_dict, section_name_dict\n",
    "\n",
    "\n",
    "# get task dictionary by name\n",
    "def get_task_dict(todoist_api):\n",
    "    api = TodoistAPI(todoist_api)\n",
    "    try:\n",
    "        todoistpull = api.get_tasks()\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "\n",
    "    # put in dictionaries\n",
    "    task_dict = {}\n",
    "    for i in range(len(todoistpull)):\n",
    "        task_dict[todoistpull[i].content] = todoistpull[i].id\n",
    "    return task_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- validation --\n",
    "# this represents a list of current limitations\n",
    "def validate_input_fields(todoist_dict, dfcsv):\n",
    "    \n",
    "    # limitation 1: all label, project, sections must pre-exist in Todoist\n",
    "    fieldname_list = ['label','project','section']\n",
    "    for fieldname in fieldname_list:\n",
    "        entry_exist = []\n",
    "        for x in dfcsv[fieldname].tolist():\n",
    "            entry_exist.append(x in todoist_dict[fieldname].keys())\n",
    "        \n",
    "        if all(entry_exist):\n",
    "            print(f'all {fieldname} found in Todoist')\n",
    "        else:\n",
    "            errormsg = f'Some {fieldname} entry does not exist in Todoist. Current code can not accomodate'\n",
    "            raise Exception(errormsg)\n",
    "    \n",
    "    \n",
    "    # limitation 2: only children level 2 can be handled\n",
    "    if dfcsv.order[0] != 1 or any(dfcsv.order > 2):\n",
    "        raise Exception('order number incorrect')\n",
    "\n",
    "    \n",
    "    # limitation 3: freq_offset must be entered, even for children task that uses days_from_parent as date calculations\n",
    "    if any(dfcsv.freq_offset.isna()):\n",
    "        raise Exception('freq_offset field must not be NaN')\n",
    "\n",
    "\n",
    "    # limitation 4: all task must have time assigned\n",
    "    if any(dfcsv.time.isna()):\n",
    "        raise Exception('time field must not be NaN')\n",
    "\n",
    "    # limitation 5: subtask backwards 27 days max\n",
    "    if any(dfcsv.days_from_parent) < -28:\n",
    "        raise Exception('code can not accomodate subtask backwards 27 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with X weekday of the month\n",
    "# get first month's third thu and next month's third thu and give the one that's after start date and before end date\n",
    "def get_X_weekday_of_month(startdate, enddate, weeknum, freq_offset):\n",
    "    thedate = []\n",
    "    # get the first month's third thu\n",
    "    d1 = pd.to_datetime(startdate) + pd.offsets.MonthBegin(n=-1)\n",
    "    dlist = pd.date_range(d1, enddate, freq=freq_offset)\n",
    "    dlist = dlist[weeknum-1] # 2 because the first value index is 0\n",
    "    # check if is after start date\n",
    "    if dlist >= startdate:\n",
    "        thedate = dlist\n",
    "    else:\n",
    "        # get the second month's third thu\n",
    "        d2 = pd.to_datetime(startdate) + pd.offsets.MonthBegin(n=1)\n",
    "        dlist = pd.date_range(d2, enddate, freq=freq_offset)\n",
    "        dlist = dlist[weeknum-1] # 2 because the first value index is 0\n",
    "        if dlist <= enddate:\n",
    "            thedate = dlist\n",
    "        else:\n",
    "            thedate = []\n",
    "            raise Exception('no date within the specified range') \n",
    "    thedate = thedate.to_pydatetime()    \n",
    "    print(thedate)      \n",
    "    return thedate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- create date list from date requirements requirements --\n",
    "# if weeknum is none, then deal with offset and freq normally\n",
    "def get_datelist(startdate, enddate, tasknow):\n",
    "    if tasknow.weeknum != 0:\n",
    "        print('weeknum detected')\n",
    "        # check if has weeknum off set, if yes, then need other calculation\n",
    "        datelist = get_X_weekday_of_month(startdate, enddate, tasknow.weeknum, tasknow.freq_offset)\n",
    "    else:\n",
    "        print('weeknum not detected')\n",
    "        if tasknow.weekstart == 0:\n",
    "            datelist = pd.date_range((startdate), enddate, freq=tasknow.freq_offset)       \n",
    "        elif tasknow.weekstart != 0:\n",
    "            datelist = pd.date_range((startdate + pd.DateOffset(tasknow.weekstart)), enddate, \n",
    "                        freq=tasknow.freq_offset)\n",
    "        else:\n",
    "            raise Exception('weekstart entry invalid')\n",
    "    return datelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- build recurrent date + time --\n",
    "def build_recurrent_datetime(datelist, tasknow_df,tasknow):\n",
    "    # build date/time string\n",
    "    datetimestr = []\n",
    "    # convert to datetime format\n",
    "    if type(datelist) is datetime.datetime:\n",
    "        datetimestr.append(datelist.strftime(\"%Y-%m-%d\") + ' ' + tasknow.time)\n",
    "    else:\n",
    "        datelist = datelist.to_pydatetime()\n",
    "        for k in range(len(datelist)):\n",
    "            a = datelist[k].strftime(\"%Y-%m-%d\") + ' ' + tasknow.time\n",
    "            datetimestr.append(a)\n",
    "        \n",
    "    # convert to datetime format\n",
    "    datetimestr = pd.to_datetime(datetimestr)\n",
    "    \n",
    "    # convert to RC3339 format\n",
    "    due_datetime = []\n",
    "    for k in range(len(datetimestr)):\n",
    "        due_datetime.append(datetimestr[k].isoformat('T'))\n",
    "    # interim report \n",
    "    print(f'{len(due_datetime)} dates generated from freq offset \"{tasknow.freq_offset}\"')\n",
    "    # add time series to dataframe\n",
    "    tasknow_df['due_datetime'] = due_datetime\n",
    "    return tasknow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add task attributes\n",
    "def add_task_attributes(tasknow, tasknow_df,todoist_dict):\n",
    "    # -- build each task for todoist --\n",
    "    # + duration to content\n",
    "    content = f'{tasknow.content} [{tasknow.duration}m]'\n",
    "    print(f'task name: {content}')\n",
    "    tasknow_df['content'] = content\n",
    "\n",
    "    # -- add the rest of task attributes --\n",
    "    # add priority\n",
    "    tasknow_df['priority'] = tasknow.priority\n",
    "    # get section id\n",
    "    sec_id = todoist_dict['section'][tasknow.section]\n",
    "    # get section id to df\n",
    "    tasknow_df['section_id'] = sec_id\n",
    "    # get project id to df\n",
    "    tasknow_df['project_id'] = todoist_dict['section_project'][sec_id]\n",
    "    # translate label \n",
    "    # <can only take one label at a time, can expand to take multiple later>\n",
    "    tasknow_df['label_ids'] = todoist_dict['label'][tasknow.label]\n",
    "    return tasknow_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tasks from list to Todoist\n",
    "def create_task_from_tasknow_df(tasknow_df, todoist_api):\n",
    "    for recur_num in range(len(tasknow_df)):\n",
    "        api = TodoistAPI(todoist_api)\n",
    "        try:\n",
    "            task = api.add_task(\n",
    "                    content=tasknow_df.content[recur_num],\n",
    "                    due_lang='en',\n",
    "                    project_id=int(tasknow_df.project_id[recur_num]),\n",
    "                    section_id=int(tasknow_df.section_id[recur_num]),\n",
    "                    due_datetime=tasknow_df.due_datetime[recur_num],\n",
    "                    priority=int(tasknow_df.priority[recur_num]),\n",
    "                    label_ids=[int(tasknow_df.label_ids[recur_num])],\n",
    "            )\n",
    "        except Exception as error:\n",
    "            print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Todoist API token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (todoist_token_fname) as f:\n",
    "    todoist_api = f.readlines()\n",
    "    todoist_api = todoist_api[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get todoist data\n",
    "label_dict = get_label_dict(todoist_api)\n",
    "proj_dict = get_project_dict(todoist_api)\n",
    "section_proj_dict, section_name_dict = get_section_dict(todoist_api)\n",
    "\n",
    "# make todoist dictionary\n",
    "todoist_dict = {}\n",
    "todoist_dict['label'] = label_dict\n",
    "todoist_dict['project'] = proj_dict\n",
    "todoist_dict['section'] = section_name_dict\n",
    "todoist_dict['section_project'] = section_proj_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start date: 2022-08-22 00:00:00\n",
      "end date: 2022-09-18 00:00:00\n",
      "duration (days): 28 days\n"
     ]
    }
   ],
   "source": [
    "# make start and end date timestamp\n",
    "startdate = pd.to_datetime(startdate_string) \n",
    "enddate = startdate + pd.DateOffset(entryduration-1)\n",
    "# report out\n",
    "print(f'start date: {startdate}')\n",
    "print(f'end date: {enddate}')\n",
    "print(f'duration (days): {entryduration} days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all label found in Todoist\n",
      "all project found in Todoist\n",
      "all section found in Todoist\n"
     ]
    }
   ],
   "source": [
    "# import csv to deal wtih the data\n",
    "dfcsv = pd.read_csv(fpath_inputcsv)\n",
    "# validate entries\n",
    "validate_input_fields(todoist_dict, dfcsv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content                  Allyship meeting\n",
       "duration                               60\n",
       "date                               16-Aug\n",
       "time                                13:00\n",
       "freq_offset                         W-TUE\n",
       "order                                   1\n",
       "days_from_parent                        0\n",
       "offset_start                            0\n",
       "weeknum                                 3\n",
       "recurrent_string    3rd Tues of the month\n",
       "priority                                4\n",
       "project                              Test\n",
       "section                        Work stuff\n",
       "label                            Computer\n",
       "Unnamed: 14                           NaN\n",
       "Unnamed: 15                           NaN\n",
       "Unnamed: 16                           NaN\n",
       "Unnamed: 17                           NaN\n",
       "Unnamed: 18                           NaN\n",
       "Name: 15, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weeknum detected\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=8'>9</a>\u001b[0m tasknow_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=10'>11</a>\u001b[0m \u001b[39m# get date list\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=11'>12</a>\u001b[0m datelist \u001b[39m=\u001b[39m get_datelist(startdate, enddate, tasknow)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=12'>13</a>\u001b[0m \u001b[39m# check if has time, if not, no date+time needed\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=13'>14</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=14'>15</a>\u001b[0m \u001b[39m# build recurrent date + time\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=15'>16</a>\u001b[0m tasknow_df \u001b[39m=\u001b[39m build_recurrent_datetime(datelist, tasknow_df, tasknow)\n",
      "\u001b[1;32m/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb Cell 19\u001b[0m in \u001b[0;36mget_datelist\u001b[0;34m(startdate, enddate, tasknow)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mweeknum detected\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=5'>6</a>\u001b[0m     \u001b[39m# check if has weeknum off set, if yes, then need other calculation\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=6'>7</a>\u001b[0m     datelist \u001b[39m=\u001b[39m get_X_weekday_of_month(startdate, enddate, tasknow\u001b[39m.\u001b[39;49mweeknum, tasknow\u001b[39m.\u001b[39;49mfreq_offset)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=7'>8</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mweeknum not detected\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb Cell 19\u001b[0m in \u001b[0;36mget_X_weekday_of_month\u001b[0;34m(startdate, enddate, weeknum, freq_offset)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=13'>14</a>\u001b[0m d2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(startdate) \u001b[39m+\u001b[39m pd\u001b[39m.\u001b[39moffsets\u001b[39m.\u001b[39mMonthBegin(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=14'>15</a>\u001b[0m dlist \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mdate_range(d2, enddate, freq\u001b[39m=\u001b[39mfreq_offset)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=15'>16</a>\u001b[0m dlist \u001b[39m=\u001b[39m dlist[weeknum\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m] \u001b[39m# 2 because the first value index is 0\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m dlist \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m enddate:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/connylin/Code/proj/todoist/todoist_csv4wk.ipynb#ch0000035?line=17'>18</a>\u001b[0m     thedate \u001b[39m=\u001b[39m dlist\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Todoist/lib/python3.10/site-packages/pandas/core/indexes/base.py:5039\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5036\u001b[0m \u001b[39mif\u001b[39;00m is_integer(key) \u001b[39mor\u001b[39;00m is_float(key):\n\u001b[1;32m   5037\u001b[0m     \u001b[39m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[1;32m   5038\u001b[0m     key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mcast_scalar_indexer(key, warn_float\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 5039\u001b[0m     \u001b[39mreturn\u001b[39;00m getitem(key)\n\u001b[1;32m   5041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[1;32m   5042\u001b[0m     \u001b[39m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[1;32m   5043\u001b[0m     \u001b[39m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[1;32m   5044\u001b[0m     result \u001b[39m=\u001b[39m getitem(key)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Todoist/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py:341\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mThis getitem defers to the underlying array, which by-definition can\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[39monly handle list-likes, slices, and integer scalars\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39m# Use cast as we know we will get back a DatetimeLikeArray or DTScalar,\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39m# but skip evaluating the Union at runtime for performance\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[39m# (see https://github.com/pandas-dev/pandas/pull/44624)\u001b[39;00m\n\u001b[1;32m    340\u001b[0m result \u001b[39m=\u001b[39m cast(\n\u001b[0;32m--> 341\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mUnion[DatetimeLikeArrayT, DTScalarOrNaT]\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key)\n\u001b[1;32m    342\u001b[0m )\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m lib\u001b[39m.\u001b[39mis_scalar(result):\n\u001b[1;32m    344\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Todoist/lib/python3.10/site-packages/pandas/core/arrays/_mixins.py:272\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[39mself\u001b[39m: NDArrayBackedExtensionArrayT,\n\u001b[1;32m    268\u001b[0m     key: PositionalIndexer2D,\n\u001b[1;32m    269\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDArrayBackedExtensionArrayT \u001b[39m|\u001b[39m Any:\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m lib\u001b[39m.\u001b[39mis_integer(key):\n\u001b[1;32m    271\u001b[0m         \u001b[39m# fast-path\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ndarray[key]\n\u001b[1;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    274\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_box_func(result)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "# process each task \n",
    "# rotate through each row\n",
    "i = 15\n",
    "# get task info\n",
    "tasknow = dfcsv.loc[i,:]\n",
    "display(tasknow)\n",
    "\n",
    "# start a new dataframe for this task\n",
    "tasknow_df = pd.DataFrame()\n",
    "\n",
    "# get date list\n",
    "datelist = get_datelist(startdate, enddate, tasknow)\n",
    "# check if has time, if not, no date+time needed\n",
    "\n",
    "# build recurrent date + time\n",
    "tasknow_df = build_recurrent_datetime(datelist, tasknow_df, tasknow)\n",
    "# add task attributes\n",
    "tasknow_df = add_task_attributes(tasknow, tasknow_df, todoist_dict)\n",
    "tasknow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep Allyship meeting\n",
      "Allyship impact note\n",
      "Determine allyship topic\n",
      "Finalize Allyship content\n"
     ]
    }
   ],
   "source": [
    "# -- deal with children task -- (option 1)\n",
    "# order - check if this task belong to a parent task \n",
    "if i != (len(dfcsv)-1): # if this task is not he last task\n",
    "    if dfcsv.loc[i+1,'order'] !=1: # if the next task is children \n",
    "        # find index to last children task\n",
    "        order_is_1 = dfcsv.loc[i+1:len(dfcsv), 'order'] == 1 # see which subsquent tasks are parent (order = 1)\n",
    "        # see if any parent task left\n",
    "        if sum(order_is_1) == 0: # if no more parent task left\n",
    "            ind_last_children = len(dfcsv)-1\n",
    "        else:\n",
    "            ind_last_children = min(order_is_1.index[order_is_1.tolist()]) - 1\n",
    "        \n",
    "        children_task_dict = {} # create children task dictionary\n",
    "        for j in range(i+1,ind_last_children): # loop through children task\n",
    "            print(dfcsv.loc[j,'content']) # print children task content\n",
    "            df = pd.DataFrame() # create data frame\n",
    "            # build df for each children task\n",
    "            \n",
    "            # store the task number for the upcoming children task\n",
    "            # calculate dates based on parent task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2022-08-25T13:00:00\n",
       "1    2022-09-01T13:00:00\n",
       "2    2022-09-08T13:00:00\n",
       "3    2022-09-15T13:00:00\n",
       "Name: due_datetime, dtype: object"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasknow_df.due_datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 dates generated from freq offset \"2W-THU\"\n",
      "task name: SC Biweekly Lead Sync [45m]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# create tasks from list to Todoist\n",
    "create_task_from_tasknow_df(tasknow_df, todoist_api)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 dates generated from freq offset \"W-SAT\"\n",
      "task name: Weekend Beauty Routine [120m]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are problem with the project id / section id dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Todoist')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3433216a67fc827b02982155d829cc9aa50b418113a1611aab43a491120dcfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
